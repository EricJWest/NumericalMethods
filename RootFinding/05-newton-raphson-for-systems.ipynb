{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root Finding for Systems of Equations: Newton-Raphson\n",
    "---\n",
    "\n",
    "GENERAL PROBLEM: find the simultaneous roots of a system of $N$ non-linear functions \n",
    "$f_{1}(x_{1},\\ldots,x_{N}), \\dots, f_{N}(x_{1},\\ldots,x_{N})$, in $N$ variables $x_{1},\\ldots,x_{N}$. That is, find a combination of $x_{1},\\ldots,x_{N}$ that satisfy the system of equations\n",
    "\n",
    "\\begin{align}\n",
    "  \\left.\\begin{array}{l}\n",
    "    f_{1}(x_{1}, \\ldots, x_{N}) = 0 \\\\\n",
    "    \\quad\\vdots \\quad\\quad\\vdots \\quad\\quad\\vdots \\\\\n",
    "    f_{N}(x_{1}, \\ldots, x_{N}) = 0\n",
    "  \\end{array}\\right\\}\n",
    "  \\quad\\leftrightarrow\\quad\n",
    "  \\mathbf{f}(\\mathbf{x}) = \\mathbf{0}\n",
    "\\end{align}\n",
    "\n",
    "IDEA: generalize the Newton-Raphson method to systems of of equations, leading to a vectorized iteration scheme.\n",
    "\n",
    "PRE-REQUISITES:   \n",
    "- Newton-Raphson method for a single equavariable\n",
    "- Solving systems of linear equations (LU decomposition, Gaussian elimination, etc)\n",
    "\n",
    "REFERENCES:\n",
    "- [1] Burden and Faires, *Numerical Analysis, 7th edition*.\n",
    "- [2] Ralston and Rabinowitz, *A First Course in Numerical Analysis, 2nd edition*.\n",
    "- [3] Press et al, *Numerical Recipes: the Art of Scientific Computing, 3rd edition*.\n",
    "- [4] Stoer and Bulirsch, *Introduction to Numerical Analysis, 2nd edition*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Review of Newton-Raphson for a single variable\n",
    "\n",
    "Briefly recall the Newton-Raphson method for a single variable. We want to find solutions to the non-linear equation $f(x)=0$. If the equation were linear, it would be trivial to solve for x. But in general when the equation is non-linear, it may be difficult to find its roots. The idea behind the Newton-Raphson method is to replace the original non-linear equation with a linear approximation to the function at a given point (i.e., a tangent line), and then solve the resulting linear problem (i.e., find the zero-crossing of that tangent line). When things go right, the solution to the linearized problem gives an improved approximant to the solution of the non-linear problem, which can then be used to construct a new linear problem (i.e., new tangent line whose zero-crossing is even closer to the searched-for root). The process is then iterated until the solution is found. \n",
    "\n",
    "To start the process, we expand the function $f(x)$ around an initial guess $x_{0}$, to first order in $(x-x_{0})$, giving\n",
    "\n",
    "\\begin{align}\n",
    "  f(x) \\approx f(x_{0}) + (x - x_{0})f'(x_{0}).\n",
    "\\end{align}\n",
    "\n",
    "Evaluating this at the root $x=x_{*}$ makes the left hand side vanish (since $f(x_{*})=0$). Re-arranging gives an approximant for the root\n",
    "\n",
    "\\begin{align}\n",
    "   x_{*} \\approx x_{0} - \\frac{f(x_{0})}{f'(x_{0})}.\n",
    "\\end{align}\n",
    "\n",
    "This is then used as the basis for an iteration scheme, using the iteration formula\n",
    "\n",
    "\\begin{align}\n",
    "  x_{i+1} = x_{i} - \\frac{f(x_{i})}{f'(x_{i})}.\n",
    "\\end{align}\n",
    "\n",
    "If the derivative of the function is not available, one may approximate it in some way. For example, substituting $f'(x_{i})$ with a forward-difference approximation gives\n",
    "\n",
    "\\begin{align}\n",
    "  x_{i+1} = x_{i} - \\frac{(x_{i} - \\delta{x_{i}})f(x_{i})}{f(x_{i} + \\delta{x_{i}}) - f(x_{i})}.\n",
    "\\end{align}\n",
    "\n",
    "Recall that one needs to take care in choosing $\\delta{x_{i}}$ at each iteration in order to keep the solution from diverging on the one hand (if $\\delta{x_{i}}$ is taken to be too large), or from being overrun by round-off error (if $\\delta{x_{i}}$ is taken to be too small)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extending Newton-Raphson to systems of equations\n",
    "\n",
    "Now we want to find solutions to the *system* of non-linear equations \n",
    "\n",
    "\\begin{align}\n",
    "  f_{1}(x_{1}, \\ldots, x_{N}) = 0 \\\\\n",
    "  \\quad\\vdots \\quad\\quad\\vdots \\quad\\quad\\vdots \\\\\n",
    "  f_{N}(x_{1}, \\ldots, x_{N}) = 0\n",
    "\\end{align}\n",
    "\n",
    "which we can write in vector form as\n",
    "\n",
    "\\begin{align}\n",
    "  \\mathbf{f}(\\mathbf{x}) = \\mathbf{0}\n",
    "  \\quad,\\quad\\text{where}\\quad\\quad\n",
    "  \\mathbf{f}(\\mathbf{x}) = \n",
    "    \\left[\\begin{array}{c}\n",
    "      f_{1}(\\mathbf{x})\\\\\n",
    "      \\vdots \\\\\n",
    "      f_{N}(\\mathbf{x})\n",
    "    \\end{array}\\right]\n",
    "  \\quad,\\quad\n",
    "  \\mathbf{x} = (x_{1}, \\ldots, x_{N})\n",
    "\\end{align}\n",
    "\n",
    "Notice that if the system of equations were linear, we could use something akin to Gaussian elimination to solve it. Since the equations are non-linear, the problem is not as easy. However, the basic idea behind Newton-Raphson (and in fact many root-finding methods) is to turn a difficult non-linear problem into a sequence of easier linear problems. Here we simply generalize the process to more than one variable.\n",
    "\n",
    "As with the single variable case, we start by expanding $\\mathbf{f}(\\mathbf{x})$ around an initial guess $\\mathbf{x}_{0}$, to first order in $(\\mathbf{x}-\\mathbf{x}_{0})$, giving\n",
    "\n",
    "\\begin{align}\n",
    "  \\mathbf{f}(\\mathbf{x}) \\approx \\mathbf{f}(\\mathbf{x}_{0}) \n",
    "  + (\\mathbf{x} - \\mathbf{x}_{0})\\cdot\\mathbf{J}(\\mathbf{x}_{0})\n",
    "\\end{align}\n",
    "\n",
    "where $\\mathbf{J}(\\mathbf{x})$ is the Jacobian matrix given by\n",
    "\n",
    "\\begin{align}\n",
    "  \\mathbf{J}(\\mathbf{x}) =\n",
    "  \\left[\\begin{array}{ccc}\n",
    "    \\frac{\\partial f_{1}}{\\partial x_{1}}(\\mathbf{x}) \n",
    "    & \\cdots & \\frac{\\partial f_{1}}{\\partial x_{N}}(\\mathbf{x}) \\\\\n",
    "    \\vdots & \\ddots & \\vdots\\\\\n",
    "    \\frac{\\partial f_{N}}{\\partial x_{1}}(\\mathbf{x}) \n",
    "    & \\cdots & \\frac{\\partial f_{N}}{\\partial x_{N}}(\\mathbf{x}) \\\\\n",
    "  \\end{array}\\right]\n",
    "  \\quad\\quad\\text{or}\\quad\\quad\n",
    "  J_{ij}(\\mathbf{x}) = \\frac{\\partial f_{i}}{\\partial x_{j}}(\\mathbf{x}).\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Evaluating this at the root $\\mathbf{x}=\\mathbf{x}_{*}$ makes the left hand side vanish (since $\\mathbf{f}(\\mathbf{x}_{*})=\\mathbf{0}$). Re-arranging gives an approximant for the root\n",
    "\n",
    "\\begin{align}\n",
    "   \\mathbf{x}_{*} \\approx \\mathbf{x}_{0} - \\mathbf{J}^{-1}(\\mathbf{x}_{0})\\cdot\\mathbf{f}(\\mathbf{x}_{0}).\n",
    "\\end{align}\n",
    "\n",
    "This is then used as the basis for an iteration scheme. In close analogy with the single variable case, the iteration equation can be written as\n",
    "\n",
    "\\begin{align}\n",
    "   \\mathbf{x}_{i+1} \\approx \\mathbf{x}_{i} - \\mathbf{J}^{-1}(\\mathbf{x}_{i})\\cdot\\mathbf{f}(\\mathbf{x}_{i}).\n",
    "\\end{align}\n",
    "\n",
    "However in practice it is not necessary to construct $\\mathbf{J}^{-1}$ explicitly, which can be computationally expensive. It is enough to solve for $\\mathbf{\\delta x}$ at each iteration and then use that to obtain an improved approximant. This two-step process is represented as\n",
    "\n",
    "\\begin{align}\n",
    "  &\\text{Step 1:}\\quad \\mathbf{J}(\\mathbf{x}_{i})\\cdot\\mathbf{\\delta x}_{i} = -\\mathbf{f}(\\mathbf{x}_{i})\n",
    "  \\quad\\text{(solve for $\\mathbf{\\delta x}_{i}$)}\\\\\n",
    "  &\\text{Step 2:}\\quad \\mathbf{x}_{i+1} = \\mathbf{x}_{i} + \\mathbf{\\delta x}_{i}\\\n",
    "\\end{align}\n",
    "\n",
    "Notice that in step 1 we need to find a solution to a system of linear equations using something akin to Gaussian elimination. Although this is not trivial, it is easier than our original problem. What we have done, in other words, is trade the difficult problem of finding a solution to a system of *non-linear* equations for a *sequence* of simpler tasks: that of solving *linear* systems of equations. The catch is that we have to do this repeatedly. No big deal if we have enough time and computing power. (Various methods have been developed to reduce, or shift, this computational effort. See [3] or [4] for further discussion.)\n",
    "\n",
    "Having solved the linear system at one iteration, we obtain a new and improved approximant to the solution. That is then used to generate a new linear system to be solved. The process is repeated until the solution is found to the desired precision (or maximum allowed iterations is reached). As with the one-dimensional Newton-Raphson method, success depends on starting with a sufficiently close initial approximant. For that reason, the method is best used in tandem with a more globally robust method such as a gradient descent method. That method will be described elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Algorithm\n",
    "\n",
    "**INPUT**\n",
    "- $\\mathbf{x}_{0}$, initial guess for the root of the system of equations in question.\n",
    "- TOL, the relative error tolerance that the answer is required to have.\n",
    "- $i_\\mathrm{max}$, maximum number of iterations allowed.\n",
    "\n",
    "**Initialize loop**\n",
    "- set $i = 0$\n",
    "\n",
    "**Loop** while $i \\leq i_\\mathrm{max}$\n",
    "\n",
    "\n",
    "- calculate $\\mathbf{f}(\\mathbf{x}_{i})$, $\\mathbf{J}(x_{i})$\n",
    "\n",
    "\n",
    "- solve $\\mathbf{J}(x_{i})\\cdot\\mathbf{\\delta x}_{i} = -\\mathbf{f}(\\mathbf{x}_{i})$\n",
    "\n",
    "\n",
    "- calculate $\\mathbf{x}_{i+1} = \\mathbf{x}_{i} + \\mathbf{\\delta x}_{i}$\n",
    "\n",
    "\n",
    "- save result\n",
    "\n",
    "\n",
    "- calculate the relative uncertainty using: REL $= ||\\mathbf{x}_{i+1} - \\mathbf{x}_{i}||\\,\\,/\\,\\, ||\\mathbf{x}_{i+1}||$\n",
    "\n",
    "\n",
    "- calculate ABS $= ||\\mathbf{f}(\\mathbf{x}_{i+1})||$\n",
    "\n",
    "\n",
    "- if (REL $\\leq$ TOL) and (ABS $\\leq$ TOL), stop. Otherwise, continue.\n",
    "\n",
    "\n",
    "- rotate $\\mathbf{x}_\\mathrm{old} = \\mathbf{x}_\\mathrm{new}$\n",
    "\n",
    "\n",
    "**Max iterations reached**\n",
    "- Print message that max iterations have been reached, and stop.\n",
    "\n",
    "**OUTPUT**\n",
    "\n",
    "solution found, or message of failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CODE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting newton_raphson2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile newton_raphson2.py\n",
    "import numpy as np\n",
    "import numpy.linalg as la \n",
    "import sys\n",
    "def newton_raphson(F, J, X0, TOL, imax):\n",
    "    \"\"\"\n",
    "    Function that searches for solution of a system of equations,\n",
    "    F(X)=0, using the Newton-Raphson method.\n",
    "    \n",
    "    INPUT\n",
    "    F    : function making up the system of equations \n",
    "    J    : Jacobian of first derivatives\n",
    "    X0   : array of initial guesses for solution\n",
    "    TOL  : allowed tolerance\n",
    "    imax : maximum number of iterations\n",
    "    \n",
    "    OUTPUT\n",
    "    solution to within the allowed tolerance, or failure message\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize output array\n",
    "    solns = []\n",
    "    \n",
    "    # initialize iteration\n",
    "    XOld = X0 # set initial approximant\n",
    "    print('Initial guess for solution',X0)\n",
    "    \n",
    "    # iterate search using method of false position\n",
    "    i = 0  # reset iteration number\n",
    "    while i <= imax:\n",
    "\n",
    "        # announce start of next iteration\n",
    "        print('Iteration',i,':')\n",
    "\n",
    "        # get function values\n",
    "        FOld = F(XOld)\n",
    "\n",
    "        # get Jacobian values\n",
    "        JOld = J(XOld) \n",
    "        \n",
    "        # solve for DX in J*DX = -F\n",
    "        A = JOld\n",
    "        b = -FOld\n",
    "        # linear algebra solver\n",
    "        DX = la.solve(A, b) \n",
    "        \n",
    "        # update approximate location of root\n",
    "        XNew = XOld + DX\n",
    "        print('  approximate location of root at',XNew)\n",
    "    \n",
    "        # calculate errors\n",
    "        XErr = la.norm(XNew - XOld, 2)\n",
    "        REL  = XErr/la.norm(XNew, 2)\n",
    "        ABS  = la.norm(F(XNew), 2)\n",
    "\n",
    "        # save approximant and error\n",
    "        solns.append([XNew, REL, ABS])\n",
    "\n",
    "        # check if errors are within the allowed tolerance\n",
    "        if (REL <= TOL and ABS <= TOL):\n",
    "            best   = XNew  #best estimate\n",
    "            uncert = XErr  #uncertainty\n",
    "            print('SUCCESS! Solution found within the specified tolerance after',i,'iterations.')\n",
    "            print('Solution is',best,'+/-',uncert)\n",
    "            return solns\n",
    "                \n",
    "        # rotate approximants\n",
    "        XOld = XNew\n",
    "\n",
    "        # increment iteration number\n",
    "        i = i + 1\n",
    "        \n",
    "    # print message that max iteration has been reached\n",
    "    print('FAIL! Max number of iterations has been reached. Stopping.')\n",
    "    \n",
    "    return solns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run newton_raphson2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. A simple 2D example\n",
    "\n",
    "(Ralston and Rabinowitz, example 8.7)\n",
    "\n",
    "The system of equations\n",
    "\n",
    "\\begin{align}\n",
    "  & f_{1}(x, y) = x^2 - y - 1 \\\\\n",
    "  & f_{2}(x, y) = (x - 2)^2 + (y - 0.5)^2 - 1\n",
    "\\end{align}\n",
    "\n",
    "has two solutions\n",
    "\n",
    "\\begin{align}\n",
    "  & r_{1} = [1.54634288332, 1.39117631279] \\\\\n",
    "  & r_{2} = [1.06734608581, 0.139227666887]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system of equations\n",
    "def system(XX):\n",
    "    x = XX[0]\n",
    "    y = XX[1]\n",
    "    dim = len(XX)\n",
    "    f = np.zeros(dim)\n",
    "    f[0] = x*x - y - 1 \n",
    "    f[1] = (x - 2)**2 + (y - 0.5)**2 - 1\n",
    "    return f\n",
    "\n",
    "# Jacobian matrix elements\n",
    "def jacobian(XX):\n",
    "    x = XX[0]\n",
    "    y = XX[1]\n",
    "    dim = len(XX)\n",
    "    dfdx = np.zeros((dim, dim))\n",
    "    dfdx[0,0] = 2*x\n",
    "    dfdx[0,1] = -1\n",
    "    dfdx[1,0] = 2*(x - 2)\n",
    "    dfdx[1,1] = 2*(y - 0.5)\n",
    "    return dfdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial guess for solution [1.22 0.7 ]\n",
      "Iteration 0 :\n",
      "  approximate location of root at [ 0.4730137  -1.33424658]\n",
      "Iteration 1 :\n",
      "  approximate location of root at [ 0.87904998 -0.3921366 ]\n",
      "Iteration 2 :\n",
      "  approximate location of root at [1.0200233  0.02057406]\n",
      "Iteration 3 :\n",
      "  approximate location of root at [1.06372744 0.12960601]\n",
      "Iteration 4 :\n",
      "  approximate location of root at [1.06731826 0.13915537]\n",
      "Iteration 5 :\n",
      "  approximate location of root at [1.06734608 0.13922766]\n",
      "SUCCESS! Solution found within the specified tolerance after 5 iterations.\n",
      "Solution is [1.06734608 0.13922766] +/- 7.746683083641568e-05\n"
     ]
    }
   ],
   "source": [
    "# exact solutions\n",
    "exact1 = np.array([1.54634288332, 1.39117631279])\n",
    "exact2 = np.array([1.06734608581, 0.139227666887])\n",
    "\n",
    "# solve system\n",
    "X0 = np.array([1.22, 0.7])\n",
    "#X0 = np.array([2.0, 4.0])\n",
    "TOL = 1e-3\n",
    "IMAX = 10\n",
    "solns = newton_raphson(system, jacobian, X0, TOL, IMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x \t\t y \t\t rel_error \t abs_error\n",
      "0.47301370 \t -1.33424658 \t 1.53082940 \t 4.72918112\n",
      "0.87904998 \t -0.39213660 \t 1.06579893 \t 1.06527159\n",
      "1.02002330 \t 0.02057406 \t 0.42747518 \t 0.19123899\n",
      "1.06372744 \t 0.12960601 \t 0.10961704 \t 0.01392959\n",
      "1.06731826 \t 0.13915537 \t 0.00947847 \t 0.00010488\n",
      "1.06734608 \t 0.13922766 \t 0.00007197 \t 0.00000001\n"
     ]
    }
   ],
   "source": [
    "# print solutions\n",
    "iterations = len(solns)\n",
    "print('x \\t\\t y \\t\\t rel_error \\t abs_error')\n",
    "for i in range(iterations):\n",
    "    xsoln = solns[i][0][0]\n",
    "    ysoln = solns[i][0][1]\n",
    "    rel_err = solns[i][1]\n",
    "    abs_err = solns[i][2]\n",
    "    print('%.8f \\t %.8f \\t %.8f \\t %.8f' % (xsoln, ysoln, rel_err, abs_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. A simple 3D example\n",
    "\n",
    "(Burden and Faires, example 10.2.1)\n",
    "\n",
    "The system of equations\n",
    "\n",
    "\\begin{align}\n",
    "  & f_{1}(x, y, z) = 3x - \\cos(yz) - 0.5 \\\\\n",
    "  & f_{2}(x, y, z) = x^2 - 81(y + 0.1)^2 + \\sin(z) + 1.06\\\\\n",
    "  & f_{3}(x, y, z) = \\exp(-xy) + 20z + \\frac{10\\pi - 3}{3}\n",
    "\\end{align}\n",
    "\n",
    "has a solution near\n",
    "\n",
    "\\begin{align}\n",
    "  r_{1} = [0.5, 0.0, -0.52359877]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system of equations\n",
    "def system(XX):\n",
    "    x = XX[0]\n",
    "    y = XX[1]\n",
    "    z = XX[2]\n",
    "    dim = len(XX)\n",
    "    f = np.zeros(dim)\n",
    "    f[0] = 3*x - np.cos(y*z) - 0.5 \n",
    "    f[1] = x**2 - 81.0*(y + 0.1)**2 + np.sin(z) + 1.06\n",
    "    f[2] = np.exp(-x*y) + 20.0*z + (10.0*np.pi - 3.0)/3.0\n",
    "    return f\n",
    "\n",
    "# Jacobian matrix elements\n",
    "def jacobian(XX):\n",
    "    x = XX[0]\n",
    "    y = XX[1]\n",
    "    z = XX[2]\n",
    "    dim = len(XX)\n",
    "    dfdx = np.zeros((dim, dim))\n",
    "    dfdx[0,0] = 3.0\n",
    "    dfdx[0,1] = z*np.sin(y*z)\n",
    "    dfdx[0,2] = y*np.sin(y*z)\n",
    "    \n",
    "    dfdx[1,0] = 2.0*x\n",
    "    dfdx[1,1] = -162.0*(y + 0.1)\n",
    "    dfdx[1,2] = np.cos(z)\n",
    "\n",
    "    dfdx[2,0] = -y*np.exp(x*y)\n",
    "    dfdx[2,1] = -x*np.exp(-x*y)\n",
    "    dfdx[2,2] = 20.0\n",
    "\n",
    "    return dfdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial guess for solution [0. 0. 0.]\n",
      "Iteration 0 :\n",
      "  approximate location of root at [ 0.5        -0.01688881 -0.52359878]\n",
      "Iteration 1 :\n",
      "  approximate location of root at [ 0.50001569  0.00172004 -0.52355363]\n",
      "Iteration 2 :\n",
      "  approximate location of root at [ 5.00000133e-01  1.45705210e-05 -5.23598394e-01]\n",
      "Iteration 3 :\n",
      "  approximate location of root at [ 5.00000000e-01  1.06342783e-09 -5.23598776e-01]\n",
      "SUCCESS! Solution found within the specified tolerance after 3 iterations.\n",
      "Solution is [ 5.00000000e-01  1.06342783e-09 -5.23598776e-01] +/- 1.457504577602255e-05\n"
     ]
    }
   ],
   "source": [
    "# exact solutions\n",
    "exact1 = np.array([0.5, 0.0, -0.52359877])\n",
    "\n",
    "# solve system\n",
    "#X0 = np.array([0.1, 0.1, -0.1])\n",
    "X0 = np.array([0.0, 0.0, 0.0])\n",
    "TOL = 1e-3\n",
    "IMAX = 100\n",
    "solns = newton_raphson(system, jacobian, X0, TOL, IMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x \t\t y \t\t z \t\t rel_error \t abs_error\n",
      "0.49986969 \t 0.01946808 \t -0.52148048 \t 0.81167414 \t 0.34592446\n",
      "0.50001424 \t 0.00158877 \t -0.52355696 \t 0.02486308 \t 0.02589220\n",
      "0.50000011 \t 0.00001245 \t -0.52359845 \t 0.00217813 \t 0.00020127\n",
      "0.50000000 \t 0.00000000 \t -0.52359878 \t 0.00001720 \t 0.00000001\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "iterations = len(solns)\n",
    "print('x \\t\\t y \\t\\t z \\t\\t rel_error \\t abs_error')\n",
    "for i in range(iterations):\n",
    "    xsoln = solns[i][0][0]\n",
    "    ysoln = solns[i][0][1]\n",
    "    zsoln = solns[i][0][2]\n",
    "    rel_err = solns[i][1]\n",
    "    abs_err = solns[i][2]\n",
    "    print('%.8f \\t %.8f \\t %.8f \\t %.8f \\t %.8f' % (xsoln, ysoln, zsoln, rel_err, abs_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
